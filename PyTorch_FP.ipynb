{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNvUwN7PRHccOeHUdpDYGZQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CameronLarsonFLT/PyTorch_FP_Prediction/blob/main/PyTorch_FP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/CameronLarsonFLT/PyTorch_FP_Prediction/main/FPs.png\" width=\"450\" align=\"right\">\n",
        "\n",
        "##PyTorch FP Property Predictor\n",
        "\n",
        "> **Example script** demonstrating how to:\n",
        "- Retrieve fluorescent protein (FP) data from the **FPbase API**\n",
        "- Train a simple **PyTorch neural network**\n",
        "- Predict key **spectral / photophysical properties** from an **amino-acid sequence**\n",
        "\n",
        "**Inputs:** `protein sequence (AA)`  \n",
        "**Outputs:** `ex_max`, `em_max`, `brightness`, `pKa`, `stokes_shift`"
      ],
      "metadata": {
        "id": "4vNJCkkITE2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Example script demonstrating how to retrieve fluorescent protein data from the\n",
        "FPbase REST API and train a simple neural network using PyTorch to predict\n",
        "various spectral or photophysical properties from the amino-acid sequence.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import trange\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Property selection\n",
        "#@markdown **Accepted values for `PROPERTY_NAME`:**\n",
        "#@markdown\n",
        "#@markdown - **Spectral**\n",
        "#@markdown   - `ex_max` — excitation maximum *(nm)*\n",
        "#@markdown   - `em_max` — emission maximum *(nm)*\n",
        "#@markdown   - `stokes_shift` — excitation/emission separation *(nm)*\n",
        "#@markdown - **Photophysics**\n",
        "#@markdown   - `brightness` — FPbase brightness\n",
        "#@markdown   - `pka` — chromophore pKa\n",
        "#@markdown ---\n",
        "\n",
        "PROPERTY_NAME = \"brightness\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "Fluorescent_Protein_Seq = \"MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTFSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Frequently used Taxonomy IDs**\n",
        "#@markdown - `6100`  *(Aequoria victoria)*\n",
        "#@markdown - `86600` *(Discosoma sp)*\n",
        "#@markdown - `6118`  *(Entacmaea quadricolor)*\n",
        "#@markdown\n",
        "#@markdown - **Leave Blank to Train on Full FPbase.org Sequence Data**\n",
        "#@markdown ---\n",
        "PARENT_ORGANISM = 6100  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Epochs** *(recommended: 5000 for Spectral Properties)*\n",
        "#@markdown ---\n",
        "EPOCHS = 5000  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown **Mini-batch size** *(recommended: 16–64; 0 = full batch)*\n",
        "BATCH_SIZE = 32  #@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "LR = 1e-3\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "EXCLUDE_TERMS = (\"channelrhodopsin\", \"rcamp\", \"gcamp2\", \"cp-mkate\", \"cegfp\")\n",
        "AMINO_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# FPbase retrieval + preprocessing\n",
        "def fetch_fpbase_proteins(parent_organism) -> list:\n",
        "    \"\"\"Retrieve proteins for a given parent organism (taxid) from the FPbase API.\n",
        "    If parent_organism is None or blank, returns the full dataset.\n",
        "    \"\"\"\n",
        "    proteins: list = []\n",
        "    parent_organism = \"\" if parent_organism is None else str(parent_organism).strip()\n",
        "    if parent_organism.lower() in (\"\", \"none\", \"null\"):\n",
        "        parent_organism = \"\"\n",
        "\n",
        "    if parent_organism:\n",
        "        if not parent_organism.isdigit():\n",
        "            raise ValueError(f\"PARENT_ORGANISM must be numeric or blank. Got: {parent_organism!r}\")\n",
        "        url = f\"https://www.fpbase.org/api/proteins/?parent_organism={parent_organism}&format=json\"\n",
        "    else:\n",
        "        print(\"TRAINING ON FULL FPBASE.ORG SEQUENCE DATA\")\n",
        "        url = \"https://www.fpbase.org/api/proteins/?&format=json\"\n",
        "\n",
        "    while url:\n",
        "        print(f\"Fetching {url} …\")\n",
        "        resp = requests.get(url, timeout=60)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "\n",
        "        # FPbase sometimes returns a list; sometimes paginated dict with \"results\"\n",
        "        if isinstance(data, list):\n",
        "            proteins.extend(data)\n",
        "            break\n",
        "\n",
        "        results = data.get(\"results\", [])\n",
        "        proteins.extend(results)\n",
        "        url = data.get(\"next\")\n",
        "\n",
        "    return proteins\n",
        "\n",
        "\n",
        "def compute_stokes_shift(protein: dict) -> float | None:\n",
        "    \"\"\"Compute Stokes shift (em_max - ex_max) for the first state with both values.\"\"\"\n",
        "    for state in protein.get(\"states\", []) or []:\n",
        "        ex = state.get(\"ex_max\")\n",
        "        em = state.get(\"em_max\")\n",
        "        if ex is not None and em is not None:\n",
        "            try:\n",
        "                return float(em) - float(ex)\n",
        "            except Exception:\n",
        "                return None\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_property(protein: dict, property_name: str) -> float | None:\n",
        "    \"\"\"Extract a scalar property from a protein record.\"\"\"\n",
        "    if property_name == \"stokes_shift\":\n",
        "        return compute_stokes_shift(protein)\n",
        "    states = protein.get(\"states\", [])\n",
        "    if states and isinstance(states, list):\n",
        "        return states[0].get(property_name)\n",
        "    return None\n",
        "\n",
        "\n",
        "def one_hot_encode_sequence(seq: str, max_len: int, alphabet: str = AMINO_ALPHABET) -> np.ndarray:\n",
        "    \"\"\"One-hot encode an amino acid sequence up to max_len. Extra positions remain zeros.\"\"\"\n",
        "    aa_to_idx = {aa: i for i, aa in enumerate(alphabet)}\n",
        "    encoding = np.zeros((max_len, len(alphabet)), dtype=np.float32)\n",
        "    for i, aa in enumerate(seq[:max_len]):\n",
        "        idx = aa_to_idx.get(aa)\n",
        "        if idx is not None:\n",
        "            encoding[i, idx] = 1.0\n",
        "    return encoding\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Model\n",
        "class PropertyPredictor(nn.Module):\n",
        "    \"\"\"A simple feed-forward regressor from one-hot sequences to a scalar property.\"\"\"\n",
        "    def __init__(self, input_len: int, alphabet_size: int, hidden_dim: int = 64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_len * alphabet_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Model bundle save/load (for reuse in later cells)\n",
        "def save_model_bundle(path: str, model: nn.Module, *, max_len: int, amino_alphabet: str,\n",
        "                      property_name: str, parent_organism, hidden_dim: int = 64) -> None:\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    bundle = {\n",
        "        \"state_dict\": model.state_dict(),\n",
        "        \"max_len\": int(max_len),\n",
        "        \"amino_alphabet\": str(amino_alphabet),\n",
        "        \"property_name\": str(property_name),\n",
        "        \"parent_organism\": parent_organism,\n",
        "        \"hidden_dim\": int(hidden_dim),\n",
        "    }\n",
        "    torch.save(bundle, path)\n",
        "    # print(f\"Saved model bundle to: {path}\")\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Run: fetch -> train -> save -> plots\n",
        "print(f\"Predicting property: {PROPERTY_NAME}\")\n",
        "print(f\"Device: {DEVICE}\")\n",
        "\n",
        "# Where bundle will go (depends on property + parent organism)\n",
        "MODEL_DIR = \"models\"\n",
        "MODEL_PATH = os.path.join(\n",
        "    MODEL_DIR,\n",
        "    f\"fp_{PROPERTY_NAME}_parent{PARENT_ORGANISM if (PARENT_ORGANISM not in [None, '']) else 'ALL'}.pt\"\n",
        ")\n",
        "# print(f\"Bundle path: {MODEL_PATH}\")\n",
        "\n",
        "proteins = fetch_fpbase_proteins(parent_organism=PARENT_ORGANISM)\n",
        "proteins = [\n",
        "    p for p in proteins\n",
        "    if not any(term in (p.get(\"name\") or \"\").lower() for term in EXCLUDE_TERMS)\n",
        "]\n",
        "\n",
        "samples: list[tuple[str, float]] = []\n",
        "for protein in proteins:\n",
        "    seq = protein.get(\"seq\")\n",
        "    value = extract_property(protein, PROPERTY_NAME)\n",
        "    if seq and value is not None:\n",
        "        try:\n",
        "            samples.append((seq, float(value)))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "if not samples:\n",
        "    raise RuntimeError(f\"No valid samples retrieved for property '{PROPERTY_NAME}'.\")\n",
        "\n",
        "max_len = max(len(seq) for seq, _ in samples)\n",
        "print(f\"Usable samples: {len(samples)}\")\n",
        "print(f\"Max sequence length in dataset: {max_len}\")\n",
        "\n",
        "X = np.stack([one_hot_encode_sequence(seq, max_len, AMINO_ALPHABET) for seq, _ in samples])\n",
        "y = np.array([val for _, val in samples], dtype=np.float32)\n",
        "\n",
        "X_tensor = torch.tensor(X, dtype=torch.float32).to(DEVICE)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(1).to(DEVICE)\n",
        "\n",
        "HIDDEN_DIM = 64\n",
        "model = PropertyPredictor(input_len=max_len, alphabet_size=len(AMINO_ALPHABET), hidden_dim=HIDDEN_DIM).to(DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=float(LR))\n",
        "\n",
        "use_minibatch = (BATCH_SIZE is not None) and (int(BATCH_SIZE) > 0)\n",
        "if use_minibatch:\n",
        "    bs = int(BATCH_SIZE)\n",
        "    dataset = TensorDataset(X_tensor, y_tensor)\n",
        "    loader = DataLoader(dataset, batch_size=bs, shuffle=True, drop_last=False)\n",
        "    print(f\"Using minibatches: batch_size={bs} | steps/epoch={len(loader)}\")\n",
        "else:\n",
        "    loader = None\n",
        "    print(\"Using full-batch training.\")\n",
        "\n",
        "loss_history = []\n",
        "pbar = trange(int(EPOCHS), desc=\"Training\", unit=\"epoch\", leave=True, colour = 'cyan',bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} [ETA {remaining}] {postfix}\",\n",
        ")\n",
        "\n",
        "for epoch in pbar:\n",
        "    model.train()\n",
        "\n",
        "    if use_minibatch:\n",
        "        running_loss = 0.0\n",
        "        n_samples = 0\n",
        "\n",
        "        for xb, yb in loader:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            preds = model(xb)\n",
        "            loss = criterion(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            bsz = xb.size(0)\n",
        "            running_loss += loss.item() * bsz\n",
        "            n_samples += bsz\n",
        "\n",
        "        epoch_loss = running_loss / max(1, n_samples)\n",
        "        loss_history.append(epoch_loss)\n",
        "        pbar.set_postfix(loss=f\"{epoch_loss:.4f}\")\n",
        "\n",
        "    else:\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        preds = model(X_tensor)\n",
        "        loss = criterion(preds, y_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_history.append(loss.item())\n",
        "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "\n",
        "# Save bundle for later reuse\n",
        "save_model_bundle(\n",
        "    MODEL_PATH,\n",
        "    model,\n",
        "    max_len=max_len,\n",
        "    amino_alphabet=AMINO_ALPHABET,\n",
        "    property_name=PROPERTY_NAME,\n",
        "    parent_organism=PARENT_ORGANISM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        ")\n",
        "\n",
        "# In-sample predictions\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predictions = model(X_tensor).squeeze().detach().cpu().numpy()\n",
        "\n",
        "# Predict user-provided FP sequence (annotation)\n",
        "fp_enc = one_hot_encode_sequence(Fluorescent_Protein_Seq, max_len, AMINO_ALPHABET)\n",
        "fp_tensor = torch.tensor(fp_enc, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    fp_pred = float(model(fp_tensor).squeeze().item())\n",
        "print(f\"FP_Seq predicted {PROPERTY_NAME}: {fp_pred:.3f}\")\n",
        "\n",
        "# Plot training loss\n",
        "plt.figure()\n",
        "plt.plot(range(1, int(EPOCHS) + 1), loss_history)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Loss (MSE)\")\n",
        "plt.title(f\"Training Loss for predicting {PROPERTY_NAME}\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot predicted vs observed (in-sample)\n",
        "plt.figure()\n",
        "plt.scatter(y, predictions, alpha=0.4)\n",
        "min_val = float(min(y.min(), predictions.min(), fp_pred))\n",
        "max_val = float(max(y.max(), predictions.max(), fp_pred))\n",
        "plt.plot([min_val, max_val], [min_val, max_val], linestyle=\"--\")\n",
        "\n",
        "# Place FP_Seq on diagonal for visibility\n",
        "plt.scatter([fp_pred], [fp_pred], s=200, marker=\"o\", edgecolors=\"k\", label=\"FP_Seq\", color=\"yellow\")\n",
        "plt.annotate(\n",
        "    f\"FP_Seq\\npred={fp_pred:.2f}\",\n",
        "    xy=(fp_pred, fp_pred),\n",
        "    xytext=(10, -25),\n",
        "    textcoords=\"offset points\",\n",
        "    arrowprops=dict(arrowstyle=\"->\"),\n",
        ")\n",
        "\n",
        "plt.xlabel(f\"Observed {PROPERTY_NAME}\")\n",
        "plt.ylabel(f\"Predicted {PROPERTY_NAME}\")\n",
        "plt.title(f\"Predicted vs Observed {PROPERTY_NAME} (Sequence annotated)\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Expose trained objects for the next cell (optional convenience)\n",
        "TRAINED_MODEL = model\n",
        "TRAINED_MAX_LEN = max_len\n",
        "TRAINED_ALPHABET = AMINO_ALPHABET\n",
        "TRAINED_PROPERTY = PROPERTY_NAME\n",
        "TRAINED_MODEL_PATH = MODEL_PATH\n",
        "\n",
        "print(\"Training complete.\")\n",
        "# print(f\"Bundle path: {MODEL_PATH}\")\n"
      ],
      "metadata": {
        "id": "PZJ7p0-_JoBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466,
          "referenced_widgets": [
            "d902a38550164071b8b84bc388416266"
          ]
        },
        "outputId": "d14bb5e7-f817-4d5e-b61e-875e51305845",
        "cellView": "form"
      },
      "execution_count": 1,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting property: brightness\n",
            "Device: cuda\n",
            "Fetching https://www.fpbase.org/api/proteins/?parent_organism=6100&format=json …\n",
            "Usable samples: 148\n",
            "Max sequence length in dataset: 353\n",
            "Using minibatches: batch_size=32 | steps/epoch=5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d902a38550164071b8b84bc388416266",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/2000 [ETA ?] "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2480474032.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/CameronLarsonFLT/PyTorch_FP_Prediction/main/FP_Alternate.png\" width=\"650\" align=\"right\">\n",
        "\n",
        "\n",
        "##PyTorch Global Amino Acid Search\n",
        "\n",
        "**Determines Impact of Mutations on Defined Property**\n",
        "\n",
        "**Properties:** `ex_max`, `em_max`, `brightness`, `pKa`, `stokes_shift`"
      ],
      "metadata": {
        "id": "5zOLSdWnKK46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Greedy single-site mutation scan WITHOUT retraining:\n",
        "- prints ALL mutations with predicted value and delta vs baseline\n",
        "- builds heatmap (AA on X, site on Y) with white gridlines\n",
        "- builds jitter scatter of all mutant predictions with ±Nσ outliers annotated\n",
        "\n",
        "This cell is standalone (does not depend on variables from your reference script).\n",
        "It will use the in-memory trained model if available; otherwise it loads from a saved bundle.\n",
        "\"\"\"\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Run Global Amino Acid Search Here\n",
        "#@markdown ---\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ----------------------------\n",
        "# User inputs for this cell\n",
        "# ----------------------------\n",
        "TEMPLATE_SEQ = (\n",
        "    \"MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTFSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\"\n",
        ")\n",
        "\n",
        "# If you trained in a prior cell, TRAINED_MODEL_PATH will exist; otherwise set a path here.\n",
        "MODEL_PATH = globals().get(\"TRAINED_MODEL_PATH\", \"models/fp_stokes_shift_parent6100.pt\")\n",
        "\n",
        "# Use the canonical alphabet unless the bundle contains a different one\n",
        "DEFAULT_ALPHABET = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "# Outlier annotation parameters for scatter plot\n",
        "N_STD = 2  # annotate points beyond mean ± N_STD*std\n",
        "JITTER = 0.20\n",
        "\n",
        "# Heatmap look (optional)\n",
        "HEATMAP_FIGSIZE = (6, 6)\n",
        "HEATMAP_FACE = \"w\"   # background like your reference\n",
        "HEATMAP_CMAP = \"bwr\"       # diverging like reference\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ----------------------------\n",
        "# Model + encoding definitions\n",
        "# ----------------------------\n",
        "def one_hot_encode_sequence(seq: str, max_len: int, alphabet: str) -> np.ndarray:\n",
        "    aa_to_idx = {aa: i for i, aa in enumerate(alphabet)}\n",
        "    arr = np.zeros((max_len, len(alphabet)), dtype=np.float32)\n",
        "    for i, aa in enumerate(seq[:max_len]):\n",
        "        idx = aa_to_idx.get(aa)\n",
        "        if idx is not None:\n",
        "            arr[i, idx] = 1.0\n",
        "    return arr\n",
        "\n",
        "class PropertyPredictor(nn.Module):\n",
        "    def __init__(self, input_len: int, alphabet_size: int, hidden_dim: int = 64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_len * alphabet_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "def load_model_bundle(path: str, device: str = \"cpu\"):\n",
        "    bundle = torch.load(path, map_location=device)\n",
        "    max_len = int(bundle[\"max_len\"])\n",
        "    alphabet = str(bundle.get(\"amino_alphabet\", DEFAULT_ALPHABET))\n",
        "    property_name = str(bundle.get(\"property_name\", \"property\"))\n",
        "    hidden_dim = int(bundle.get(\"hidden_dim\", 64))\n",
        "\n",
        "    model = PropertyPredictor(input_len=max_len, alphabet_size=len(alphabet), hidden_dim=hidden_dim).to(device)\n",
        "    model.load_state_dict(bundle[\"state_dict\"])\n",
        "    model.eval()\n",
        "    return model, max_len, alphabet, property_name\n",
        "\n",
        "# ----------------------------\n",
        "# Acquire model WITHOUT training\n",
        "# ----------------------------\n",
        "if \"TRAINED_MODEL\" in globals() and \"TRAINED_MAX_LEN\" in globals() and \"TRAINED_ALPHABET\" in globals():\n",
        "    model = globals()[\"TRAINED_MODEL\"].to(DEVICE)\n",
        "    max_len = int(globals()[\"TRAINED_MAX_LEN\"])\n",
        "    alphabet = str(globals()[\"TRAINED_ALPHABET\"])\n",
        "    property_name = str(globals().get(\"TRAINED_PROPERTY\", \"property\"))\n",
        "    model.eval()\n",
        "    print(\"Using in-memory trained model.\")\n",
        "else:\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        raise FileNotFoundError(\n",
        "            f\"MODEL_PATH not found: {MODEL_PATH}\\n\"\n",
        "            \"Run your training cell first (to create the bundle), or set MODEL_PATH to an existing .pt bundle.\"\n",
        "        )\n",
        "    model, max_len, alphabet, property_name = load_model_bundle(MODEL_PATH, device=DEVICE)\n",
        "    print(f\"Loaded model bundle from: {MODEL_PATH}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Baseline prediction\n",
        "# ----------------------------\n",
        "template_enc = one_hot_encode_sequence(TEMPLATE_SEQ, max_len, alphabet)\n",
        "template_tensor = torch.tensor(template_enc, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "with torch.no_grad():\n",
        "    baseline_pred = float(model(template_tensor).squeeze().item())\n",
        "\n",
        "print(f\"\\nTemplate predicted {property_name}: {baseline_pred:.6f}\\n\")\n",
        "\n",
        "# ----------------------------\n",
        "# Greedy single-site scan (PRINT ALL MUTATIONS)\n",
        "# ----------------------------\n",
        "mutant_predictions = {}  # label -> predicted\n",
        "mutant_deltas = {}       # label -> pred - baseline\n",
        "\n",
        "n_pos = len(TEMPLATE_SEQ)\n",
        "\n",
        "for pos0, orig_aa in enumerate(TEMPLATE_SEQ):\n",
        "    site = pos0 + 1\n",
        "    for new_aa in alphabet:\n",
        "        if new_aa == orig_aa:\n",
        "            continue\n",
        "        mutated_seq = TEMPLATE_SEQ[:pos0] + new_aa + TEMPLATE_SEQ[pos0+1:]\n",
        "\n",
        "        enc = one_hot_encode_sequence(mutated_seq, max_len, alphabet)\n",
        "        x = torch.tensor(enc, dtype=torch.float32).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            pred = float(model(x).squeeze().item())\n",
        "\n",
        "        label = f\"{orig_aa}{site}{new_aa}\"\n",
        "        delta = pred - baseline_pred\n",
        "\n",
        "        mutant_predictions[label] = pred\n",
        "        mutant_deltas[label] = delta\n",
        "\n",
        "        # Print all mutations (as requested)\n",
        "        print(f\"{label}: predicted {property_name} = {pred:.6f}   Δ={delta:+.6f}\")\n",
        "\n",
        "print(f\"\\nTotal mutants evaluated: {len(mutant_predictions)}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Build a DataFrame matrix for heatmap\n",
        "# rows = sites, cols = amino acids (new residue)\n",
        "# values = predicted property (not delta) for that substitution\n",
        "# ----------------------------\n",
        "pattern = re.compile(r\"^([A-Z])(\\d+)([A-Z])$\")\n",
        "records = []\n",
        "site_set = set()\n",
        "\n",
        "for k, v in mutant_predictions.items():\n",
        "    m = pattern.match(k)\n",
        "    if not m:\n",
        "        continue\n",
        "    _, pos_s, newaa = m.groups()\n",
        "    pos = int(pos_s)\n",
        "    records.append((pos, newaa, float(v)))\n",
        "    site_set.add(pos)\n",
        "\n",
        "aa_order = list(alphabet)\n",
        "site_order = sorted(site_set)\n",
        "\n",
        "df = pd.DataFrame(index=site_order, columns=aa_order, dtype=float)\n",
        "for pos, newaa, val in records:\n",
        "    if (pos in df.index) and (newaa in df.columns):\n",
        "        df.loc[pos, newaa] = val\n",
        "\n",
        "# Fill NaNs (should only be identity AAs which we skipped) with per-row min for display\n",
        "filled = df.copy()\n",
        "if filled.isna().any().any():\n",
        "    row_mins = filled.min(axis=1)\n",
        "    for r in filled.index:\n",
        "        filled.loc[r] = filled.loc[r].fillna(row_mins[r])\n",
        "\n",
        "# ----------------------------\n",
        "# HEATMAP FIGURE (like your reference)\n",
        "# ----------------------------\n",
        "plt.figure(figsize=HEATMAP_FIGSIZE, facecolor=HEATMAP_FACE)\n",
        "ax = plt.gca()\n",
        "ax.set_facecolor(HEATMAP_FACE)\n",
        "\n",
        "# IMPORTANT: origin=\"upper\" puts site 1 at the top\n",
        "im = ax.imshow(\n",
        "    filled.values,\n",
        "    aspect=\"auto\",\n",
        "    cmap=HEATMAP_CMAP,\n",
        "    interpolation=\"nearest\",\n",
        "    origin=\"upper\"\n",
        ")\n",
        "\n",
        "# X ticks: amino acids\n",
        "ax.set_xticks(np.arange(len(aa_order)))\n",
        "ax.set_xticklabels(aa_order)\n",
        "\n",
        "# Y ticks every 10 residues (matching your reference)\n",
        "ytick_step = 10\n",
        "ytick_idx = np.arange(0, len(site_order), ytick_step)\n",
        "ax.set_yticks(ytick_idx)\n",
        "ax.set_yticklabels([site_order[i] for i in ytick_idx])\n",
        "\n",
        "# White gridlines around every cell\n",
        "ax.set_xticks(np.arange(-0.5, len(aa_order), 1), minor=True)\n",
        "ax.set_yticks(np.arange(-0.5, len(site_order), 1), minor=True)\n",
        "ax.grid(which=\"minor\", color=\"white\", linestyle=\"-\", linewidth=0.4)\n",
        "ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
        "\n",
        "# Labels and title\n",
        "ax.set_xlabel(\"Amino acid\")\n",
        "ax.set_ylabel(\"Site\")\n",
        "ax.set_title(f\"Predicted {property_name.title()}\", fontweight=\"bold\")\n",
        "\n",
        "# Colorbar\n",
        "cbar = plt.colorbar(im, ax=ax)\n",
        "cbar.set_label(f\"Predicted {property_name}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# JITTER SCATTER FIGURE (outliers annotated) + delta available in export\n",
        "# ----------------------------\n",
        "sorted_items = sorted(mutant_predictions.items(), key=lambda x: x[1], reverse=True)\n",
        "mut_labels = [k for k, _ in sorted_items]\n",
        "pred_vals = np.array([v for _, v in sorted_items], dtype=float)\n",
        "delta_vals = np.array([mutant_deltas[k] for k in mut_labels], dtype=float)\n",
        "\n",
        "mean_val = float(pred_vals.mean())\n",
        "std_val = float(pred_vals.std(ddof=0))\n",
        "upper = mean_val + N_STD * std_val\n",
        "lower = mean_val - N_STD * std_val\n",
        "\n",
        "x_jitter = np.random.uniform(-JITTER, JITTER, size=len(pred_vals))\n",
        "x_positions = x_jitter  # centered at 0\n",
        "\n",
        "plt.figure(figsize=(12, 6), facecolor=\"w\")\n",
        "ax = plt.gca()\n",
        "ax.set_facecolor(\"w\")\n",
        "\n",
        "plt.scatter(x_positions, pred_vals, s=20, alpha=0.7, color = 'k')\n",
        "\n",
        "# Annotate outliers beyond ±Nσ\n",
        "for xi, yi, label in zip(x_positions, pred_vals, mut_labels):\n",
        "    if yi > upper or yi < lower:\n",
        "        plt.annotate(\n",
        "            label,\n",
        "            (xi, yi),\n",
        "            textcoords=\"offset points\",\n",
        "            xytext=(3, 3),\n",
        "            ha=\"left\",\n",
        "            fontsize=7,\n",
        "            color=\"red\" if yi > upper else \"blue\",\n",
        "        )\n",
        "\n",
        "plt.axhline(mean_val, linestyle=\"--\", alpha=0.7, label=f\"Mean = {mean_val:.2f}\", color = 'green')\n",
        "plt.axhline(upper, linestyle=\":\", alpha=0.7, label=f\"+{N_STD}σ = {upper:.2f}\", color = 'red')\n",
        "plt.axhline(lower, linestyle=\":\", alpha=0.7, label=f\"-{N_STD}σ = {lower:.2f}\", color = 'blue')\n",
        "plt.legend()\n",
        "\n",
        "plt.ylabel(f\"Predicted {property_name.title()}\")\n",
        "plt.title(f\"Predicted {property_name.title()} of Single Point Mutants (Outliers: ±{N_STD} SD)\")\n",
        "plt.grid(False)\n",
        "plt.xticks([])  # hide meaningless x-axis\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# Optional: export ALL mutations with prediction + delta\n",
        "# ----------------------------\n",
        "out_df = pd.DataFrame({\n",
        "    \"mutation\": mut_labels,\n",
        "    \"predicted\": pred_vals,\n",
        "    \"delta_vs_template\": delta_vals,\n",
        "}).sort_values(\"predicted\", ascending=False)\n",
        "\n",
        "csv_name = f\"all_single_mutants_{property_name}.csv\"\n",
        "# out_df.to_csv(csv_name, index=False)\n",
        "# print(f\"\\nWrote full table (all mutations) to: {csv_name}\")\n"
      ],
      "metadata": {
        "id": "rW7eDC_F6pa3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "\n",
        "<h1 align=\"right\" style=\"font-size:48px;\">PyTorch-Based Design</h1>\n",
        "\n",
        "<p align=\"left\">\n",
        "  <img src=\"https://raw.githubusercontent.com/CameronLarsonFLT/PyTorch_FP_Prediction/main/FP_Design.png\" width=\"550\">\n",
        "</p>\n",
        "\n",
        "<p align=\"right\">\n",
        "<ul>\n",
        "  <li>PyTorch regressor predicts protein properties directly from amino-acid sequence</li>\n",
        "  <li>Greedy / Top-K search explores single-site mutations from a template</li>\n",
        "  <li>Mutations ranked by predicted improvement and applied iteratively</li>\n",
        "  <li>Supports deterministic or stochastic optimization paths</li>\n",
        "  <li>Outputs optimized variants as FASTA for downstream analysis</li>\n",
        "</ul>\n",
        "</p>\n",
        "\n",
        "<hr>\n"
      ],
      "metadata": {
        "id": "uBVt1WrMGLst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Greedy search to design N sequences WITHOUT retraining.\n",
        "\n",
        "Uses ONLY vars already defined in your training cell:\n",
        "- PROPERTY_NAME, AMINO_ALPHABET, DEVICE\n",
        "- TRAINED_MODEL / TRAINED_MAX_LEN / TRAINED_ALPHABET / TRAINED_PROPERTY / TRAINED_MODEL_PATH\n",
        "- Fluorescent_Protein_Seq (template)\n",
        "\n",
        "Writes ONE multi-FASTA file to OUT_DIR (template first, then designs).\n",
        "\n",
        "This version is TOP-K ONLY (always samples from top-K at each step).\n",
        "\"\"\"\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown # Run Greedy Amino Acid Search with Top-K Sampling\n",
        "#@markdown ---\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import datetime\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Objective\n",
        "#@markdown - MAXIMIZE=True for properties like brightness, stokes_shift, em_max\n",
        "#@markdown - MAXIMIZE=False for properties you want to minimize\n",
        "#@markdown ---\n",
        "MAXIMIZE = True  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Greedy step threshold (in *nm, pKa, or brightness units*)\n",
        "#@markdown A mutation is only accepted if it improves the current prediction by at least this amount.\n",
        "#@markdown ---\n",
        "STEP_THRESHOLD = 4.0  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Design controls\n",
        "#@markdown - N_DESIGNS = how many designed sequences to generate\n",
        "#@markdown - MAX_MUTATIONS = max mutations per design\n",
        "#@markdown ---\n",
        "N_DESIGNS = 10      #@param {type:\"integer\"}\n",
        "MAX_MUTATIONS = 10   #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Top-K sampling (ALWAYS ON)\n",
        "#@markdown At each step, we:\n",
        "#@markdown 1) score all single-AA mutations that pass threshold\n",
        "#@markdown 2) sort by predicted property\n",
        "#@markdown 3) randomly pick ONE from the top-K\n",
        "#@markdown ---\n",
        "TOPK_PER_STEP = 10  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Optional constraint\n",
        "#@markdown If True, don't mutate the same position twice within a design.\n",
        "#@markdown ---\n",
        "AVOID_REPEAT_POS = False  #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Output\n",
        "#@markdown ---\n",
        "OUT_DIR = \"designed_seqs_greedy\"     #@param {type:\"string\"}\n",
        "WRITE_FASTA = True                  #@param {type:\"boolean\"}\n",
        "MULTIFASTA_BASENAME = \"ALL_DESIGNS\"  #@param {type:\"string\"}\n",
        "\n",
        "# ----------------------------\n",
        "# Model helpers (must match training architecture)\n",
        "# ----------------------------\n",
        "def one_hot_encode_sequence(seq: str, max_len: int, alphabet: str) -> np.ndarray:\n",
        "    aa_to_idx = {aa: i for i, aa in enumerate(alphabet)}\n",
        "    arr = np.zeros((max_len, len(alphabet)), dtype=np.float32)\n",
        "    for i, aa in enumerate(seq[:max_len]):\n",
        "        idx = aa_to_idx.get(aa)\n",
        "        if idx is not None:\n",
        "            arr[i, idx] = 1.0\n",
        "    return arr\n",
        "\n",
        "class PropertyPredictor(nn.Module):\n",
        "    def __init__(self, input_len: int, alphabet_size: int, hidden_dim: int = 64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(input_len * alphabet_size, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "        )\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.net(x)\n",
        "\n",
        "def load_model_bundle(path: str, device: str = \"cpu\"):\n",
        "    bundle = torch.load(path, map_location=device)\n",
        "    max_len = int(bundle[\"max_len\"])\n",
        "    alphabet = str(bundle.get(\"amino_alphabet\", AMINO_ALPHABET))\n",
        "    prop = str(bundle.get(\"property_name\", PROPERTY_NAME))\n",
        "    hidden_dim = int(bundle.get(\"hidden_dim\", 64))\n",
        "\n",
        "    model = PropertyPredictor(input_len=max_len, alphabet_size=len(alphabet), hidden_dim=hidden_dim).to(device)\n",
        "    model.load_state_dict(bundle[\"state_dict\"])\n",
        "    model.eval()\n",
        "    return model, max_len, alphabet, prop\n",
        "\n",
        "def predict_seq(model: nn.Module, seq: str, max_len: int, alphabet: str, device: str) -> float:\n",
        "    enc = one_hot_encode_sequence(seq, max_len, alphabet)\n",
        "    x = torch.tensor(enc, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        return float(model(x).squeeze().item())\n",
        "\n",
        "def muts_to_labels(original_seq: str, mutated_seq: str) -> list[str]:\n",
        "    labels = []\n",
        "    for i, (a, b) in enumerate(zip(original_seq, mutated_seq)):\n",
        "        if a != b:\n",
        "            labels.append(f\"{a}{i+1}{b}\")\n",
        "    return labels\n",
        "\n",
        "def wrap_fasta(seq: str, width: int = 60) -> str:\n",
        "    return \"\\n\".join(seq[i:i+width] for i in range(0, len(seq), width))\n",
        "\n",
        "# ----------------------------\n",
        "# Acquire trained model (NO retraining)\n",
        "# ----------------------------\n",
        "if \"TRAINED_MODEL\" in globals() and \"TRAINED_MAX_LEN\" in globals() and \"TRAINED_ALPHABET\" in globals():\n",
        "    model = TRAINED_MODEL.to(DEVICE)\n",
        "    max_len = int(TRAINED_MAX_LEN)\n",
        "    trained_alphabet = str(TRAINED_ALPHABET)\n",
        "    trained_prop = str(globals().get(\"TRAINED_PROPERTY\", PROPERTY_NAME))\n",
        "    model.eval()\n",
        "    print(\"Using in-memory trained model.\")\n",
        "else:\n",
        "    if not (\"TRAINED_MODEL_PATH\" in globals()):\n",
        "        raise RuntimeError(\"TRAINED_MODEL_PATH not found. Run the training cell first.\")\n",
        "    if not os.path.exists(TRAINED_MODEL_PATH):\n",
        "        raise FileNotFoundError(f\"Model bundle not found: {TRAINED_MODEL_PATH}\")\n",
        "    model, max_len, trained_alphabet, trained_prop = load_model_bundle(TRAINED_MODEL_PATH, device=DEVICE)\n",
        "    print(f\"Loaded model bundle from: {TRAINED_MODEL_PATH}\")\n",
        "\n",
        "if trained_prop != PROPERTY_NAME:\n",
        "    print(f\"WARNING: bundle property_name={trained_prop} but current PROPERTY_NAME={PROPERTY_NAME}. Using {trained_prop}.\")\n",
        "\n",
        "alphabet = trained_alphabet\n",
        "template = Fluorescent_Protein_Seq\n",
        "scan_positions = list(range(len(template)))\n",
        "\n",
        "print(f\"Device: {DEVICE}\")\n",
        "print(f\"Property: {trained_prop} | MAXIMIZE={MAXIMIZE}\")\n",
        "print(f\"Template length: {len(template)} | max_len: {max_len}\")\n",
        "print(f\"Alphabet size used this run: {len(alphabet)}\")\n",
        "\n",
        "if bool(WRITE_FASTA):\n",
        "    os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "baseline_pred = predict_seq(model, template, max_len, trained_alphabet, DEVICE)\n",
        "print(f\"\\nTemplate predicted {trained_prop}: {baseline_pred:.6f}\\n\")\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "multifasta_path = None\n",
        "if bool(WRITE_FASTA):\n",
        "    multifasta_path = os.path.join(OUT_DIR, f\"{MULTIFASTA_BASENAME}_{trained_prop}_{timestamp}.fasta\")\n",
        "\n",
        "# ----------------------------\n",
        "# Top-K greedy design loop (single design)\n",
        "# ----------------------------\n",
        "def topk_design() -> tuple[str, float]:\n",
        "    current = template\n",
        "    current_pred = baseline_pred\n",
        "    used_positions = set()\n",
        "\n",
        "    for _step in range(1, int(MAX_MUTATIONS) + 1):\n",
        "        candidates = []  # (new_pred, delta, pos0, newaa)\n",
        "\n",
        "        for pos0 in scan_positions:\n",
        "            if bool(AVOID_REPEAT_POS) and (pos0 in used_positions):\n",
        "                continue\n",
        "            orig = current[pos0]\n",
        "            for newaa in alphabet:\n",
        "                if newaa == orig:\n",
        "                    continue\n",
        "\n",
        "                trial = current[:pos0] + newaa + current[pos0+1:]\n",
        "                trial_pred = predict_seq(model, trial, max_len, trained_alphabet, DEVICE)\n",
        "                delta = trial_pred - current_pred\n",
        "\n",
        "                if bool(MAXIMIZE):\n",
        "                    if delta >= float(STEP_THRESHOLD):\n",
        "                        candidates.append((trial_pred, delta, pos0, newaa))\n",
        "                else:\n",
        "                    if delta <= -float(STEP_THRESHOLD):\n",
        "                        candidates.append((trial_pred, delta, pos0, newaa))\n",
        "\n",
        "        if not candidates:\n",
        "            break\n",
        "\n",
        "        # Sort by objective\n",
        "        if bool(MAXIMIZE):\n",
        "            candidates.sort(key=lambda x: x[0], reverse=True)\n",
        "        else:\n",
        "            candidates.sort(key=lambda x: x[0])\n",
        "\n",
        "        # Sample ONE from top-K\n",
        "        k = max(1, min(int(TOPK_PER_STEP), len(candidates)))\n",
        "        chosen = candidates[np.random.randint(0, k)]\n",
        "\n",
        "        new_pred, _delta, pos0, newaa = chosen\n",
        "        current = current[:pos0] + newaa + current[pos0+1:]\n",
        "        current_pred = new_pred\n",
        "        used_positions.add(pos0)\n",
        "\n",
        "    return current, current_pred\n",
        "\n",
        "# ----------------------------\n",
        "# Generate N designs (duplicates allowed) + write multifasta\n",
        "# ----------------------------\n",
        "fh_multi = None\n",
        "if bool(WRITE_FASTA):\n",
        "    fh_multi = open(multifasta_path, \"w\", encoding=\"utf-8\")\n",
        "    fh_multi.write(f\">TEMPLATE_{trained_prop}_pred={baseline_pred:.6f}\\n\")\n",
        "    fh_multi.write(wrap_fasta(template) + \"\\n\")\n",
        "\n",
        "try:\n",
        "    for i in range(1, int(N_DESIGNS) + 1):\n",
        "        seq, pred = topk_design()\n",
        "        labels = muts_to_labels(template, seq)\n",
        "        delta_vs_template = pred - baseline_pred\n",
        "\n",
        "        design_name = f\"Design_{i:03d}_{trained_prop}\"\n",
        "        header = f\">{design_name}_pred={pred:.6f}_delta_vs_template={delta_vs_template:+.6f}_nmut={len(labels)}\"\n",
        "\n",
        "        print(header)\n",
        "        print(f\"Mutations: {', '.join(labels) if labels else '(none)'}\")\n",
        "        print(wrap_fasta(seq))\n",
        "        print()\n",
        "\n",
        "        if bool(WRITE_FASTA) and fh_multi is not None:\n",
        "            fh_multi.write(header + \"\\n\")\n",
        "            fh_multi.write(wrap_fasta(seq) + \"\\n\")\n",
        "finally:\n",
        "    if fh_multi is not None:\n",
        "        fh_multi.close()\n",
        "\n",
        "if bool(WRITE_FASTA):\n",
        "    print(f\"\\nMulti-FASTA written to:\\n  {multifasta_path}\")\n"
      ],
      "metadata": {
        "id": "qiO6t6I_6pk_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown # Download Dependencies to Generate MSA\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "RUN_INSTALL = True\n",
        "if RUN_INSTALL:\n",
        "    print(\"Downloading dependencies...\\n\")\n",
        "\n",
        "    from tqdm.auto import tqdm\n",
        "    import subprocess\n",
        "\n",
        "    steps = [\n",
        "        [\"apt-get\", \"-qq\", \"update\"],\n",
        "        [\"apt-get\", \"-qq\", \"install\", \"-y\", \"mafft\"],\n",
        "        [\"pip\", \"-q\", \"install\", \"pymsaviz\"],\n",
        "        [\"pip\", \"-q\", \"install\", \"biopython\"],\n",
        "    ]\n",
        "\n",
        "    with tqdm(\n",
        "        total=len(steps),\n",
        "        desc=\"\",\n",
        "        bar_format=\"{bar} {n_fmt}/{total_fmt}\",\n",
        "        colour=\"cyan\",\n",
        "    ) as pbar:\n",
        "        for cmd in steps:\n",
        "            subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)\n",
        "            pbar.update(1)\n"
      ],
      "metadata": {
        "id": "GG5R4VrN6ppJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ---\n",
        "#@markdown # Run MAFFT MSA on the multi-FASTA\n",
        "#@markdown ---\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from datetime import datetime\n",
        "import tempfile\n",
        "from collections import Counter\n",
        "\n",
        "from Bio import SeqIO, AlignIO\n",
        "from Bio.SeqRecord import SeqRecord\n",
        "from Bio.Seq import Seq\n",
        "\n",
        "try:\n",
        "    from pymsaviz import MsaViz\n",
        "except ImportError:\n",
        "    MsaViz = None\n",
        "\n",
        "from IPython.display import SVG, display\n",
        "\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Inputs / Outputs\n",
        "#@markdown ---\n",
        "INPUT_FASTA = multifasta_path  #@param {type:\"string\"}\n",
        "OUTDIR = \"msa_outputs\"         #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ## Visualization\n",
        "#@markdown ---\n",
        "WRAP_LENGTH = 90               #@param {type:\"integer\"}\n",
        "CONSENSUS_THRESHOLD = 0.501    #@param {type:\"number\"}\n",
        "MAKE_SVG = True                #@param {type:\"boolean\"}\n",
        "\n",
        "# Always do U->X; do NOT use --anysymbol\n",
        "REPLACE_U_WITH_X = True\n",
        "USE_ANY_SYMBOL = False\n",
        "\n",
        "\n",
        "def consensus_from_alignment(msa, threshold=0.501, gap_char=\"-\"):\n",
        "    L = msa.get_alignment_length()\n",
        "    out = []\n",
        "    for col in range(L):\n",
        "        syms = [rec.seq[col] for rec in msa]\n",
        "        non_gaps = [c for c in syms if c != gap_char]\n",
        "        if not non_gaps:\n",
        "            out.append(gap_char)\n",
        "            continue\n",
        "        counts = Counter(non_gaps)\n",
        "        top, n = counts.most_common(1)[0]\n",
        "        out.append(top if (n / len(non_gaps)) >= threshold else \"X\")\n",
        "    return \"\".join(out)\n",
        "\n",
        "\n",
        "def run_basic_msa(input_fasta_path: str, output_dir: str):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    with tempfile.TemporaryDirectory() as tmpdir:\n",
        "        cleaned_fasta = os.path.join(tmpdir, \"cleaned.fasta\")\n",
        "        aligned_fasta = os.path.join(tmpdir, \"aligned.fasta\")\n",
        "\n",
        "        # Clean FASTA (U->X, strip non-AA)\n",
        "        cleaned = []\n",
        "        allowed = set(\"ACDEFGHIKLMNPQRSTVWYXBZJO-\")  # exclude U because we replace it\n",
        "\n",
        "        for rec in SeqIO.parse(input_fasta_path, \"fasta\"):\n",
        "            seq = str(rec.seq).upper()\n",
        "            if REPLACE_U_WITH_X:\n",
        "                seq = seq.replace(\"U\", \"X\")\n",
        "            seq = \"\".join(c for c in seq if c in allowed)\n",
        "            if seq:\n",
        "                cleaned.append(SeqRecord(Seq(seq), id=rec.id[:50], description=\"\"))\n",
        "\n",
        "        SeqIO.write(cleaned, cleaned_fasta, \"fasta\")\n",
        "\n",
        "        # MAFFT\n",
        "        mafft = [\"mafft\", \"--auto\", cleaned_fasta]\n",
        "        proc = subprocess.run(mafft, capture_output=True, text=True)\n",
        "        if proc.returncode != 0:\n",
        "            raise RuntimeError(proc.stderr or \"MAFFT failed (no stderr)\")\n",
        "\n",
        "        with open(aligned_fasta, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(proc.stdout)\n",
        "\n",
        "        alignment = AlignIO.read(aligned_fasta, \"fasta\")\n",
        "        consensus = consensus_from_alignment(alignment, float(CONSENSUS_THRESHOLD))\n",
        "\n",
        "        aln_out = os.path.join(output_dir, f\"aligned_{timestamp}.fasta\")\n",
        "        con_out = os.path.join(output_dir, f\"consensus_{timestamp}.txt\")\n",
        "        AlignIO.write(alignment, aln_out, \"fasta\")\n",
        "        with open(con_out, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(consensus + \"\\n\")\n",
        "\n",
        "        if MAKE_SVG and MsaViz is not None:\n",
        "            svg_path = os.path.join(output_dir, f\"msa_{timestamp}.svg\")\n",
        "            viz = MsaViz(\n",
        "                aln_out,\n",
        "                wrap_length=int(WRAP_LENGTH),\n",
        "                show_label=True,\n",
        "                show_count=True,\n",
        "                show_consensus=True,\n",
        "                color_scheme=\"Identity\",\n",
        "            )\n",
        "            viz.savefig(svg_path)\n",
        "            display(SVG(filename=svg_path))\n",
        "\n",
        "\n",
        "# Run\n",
        "run_basic_msa(INPUT_FASTA, OUTDIR)\n"
      ],
      "metadata": {
        "id": "D8IvtDK56prw",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tklrWJpdYaxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aAJYATJD6puW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yWM1vDIrmMzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZU4EV3CmM3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "px4M4iXzmM5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qcJkffHL4nKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wraeDGeOmOP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85uRGh7alK3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QHdBLD1nlK6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Q-K36_8lK83"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}